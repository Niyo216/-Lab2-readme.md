# -Lab2-readme.md

# Here is a heading; Information Systems for Business and Beyond: Chapter 2 - Hardware

HARDWARE; The physical parts of computing devices – those that you can actually touch – are referred to as hardware.

# HARD DRIVES AND MEMORY

The performance of a hard disk is very important to the overall speed of the system – a slow hard disk having the potential to hinder a fast processor like no other system component – and the effective speed of a hard disk is determined by a number of factors.

# The difference between latency and transfer rates in the performance of a hard drive.

Latency is the average time for the sector being accessed to rotate into position under a head, after a completed seek. It is easily calculated from the spindle speed, being the time for half a rotation. A drive’s average access time is the interval between the time a request for data is made by the system and the time the data is available from the drive.

The disk transfer rate (sometimes called media rate) is the speed at which data is transferred to and from the disk media (actual disk platter) and is a function of the recording frequency. It is generally described in megabytes per second (MBps). Modern hard disks have an increasing range of disk transfer rates from the inner diameter to the outer diameter of the disk. This is called a zoned recording technique. The key media recording parameters relating to density per platter are Tracks Per Inch (TPI) and Bits Per Inch (BPI). A track is a circular ring around the disk. TPI is the number of these tracks that can fit in a given area (inch). BPI defines how many bits can be written onto one inch of a track on a disk surface.

The host transfer rate is the speed at which the host computer can transfer data across the IDE/EIDE or SCSI interface to the CPU. It is more generally referred to as the data transfer rate, or DTR, and can be the source of some confusion. Some vendors list the internal transfer rate, the rate at which the disk moves data from the head to its internal buffers. Others cite the burst data transfer rate, the maximum transfer rate the disk can attain under ideal circumstances and for a short duration. More important for the real world is the external data transfer rate, or how fast the hard disk actually transfers data to a PC’s main memory.

# How hard drive is different from a traditional hard drive. 

A solid state drive is a storage device that uses solid state memory to store data. While technically not a disk, a solid state drive will often be referred to as a solid state disk drive, or a solid state disk, in reference to the fact that, in some ways, it replaces the traditional hard disk drive.

The principle behind solid state drives is that there should be no moving parts: no spinning platters, no moving heads. Data is split into word length pieces and stored in memory. Solid state disks use either NAND flash or SDRAM (non-volatile and volatile storage respectively). NAND flash is so-called because of the NAND-gate technology it uses and is common in USB flash drives and many types of memory card.

Hard disk drives have been a faithful servant to computing for many years. But with heads, platters, magnetic surfaces, spindles and an array of other complex moving parts, they are most certainly fallible.

# RAM: Random Access Memory
Primary Memory or a temporary storage:

# Why does increasing RAM make the computer run faster? 
 because when the memory is too low it may not hold all the data the CPU needs. when this happens some of the data need to be kept on the slower hard drive to compansate for the low memory. so, instead of the data to go back from CPU it has to do extra work to go back to the hard drive, When this happens  it slows down the computer. In order to solve all these, you need to increse the amount of RAM on the computer, and by increasing a memory more data can be loaded in the fast RAM without the need of constantly accessing the slower hard drive.

# What is the difference between 64 and 32 bit data paths? 
The term 64 or 32 bit data path refers to the number of bits of data that are transferred in 1 clock cycle.
DIMM; Transfers 64 bits at a time.
SIMM; Transfers 32 bits at a time.

# ALU and the Control Unit 
 # The interaction of the control unit and ALU in the CPU:
 The control unit tells the ALU what operation to perform on that data and the ALU stores the result in an output register.

# IEEE - Ethically Aligned Design.
  The purpose of IEEE and the importance of ethics in device design.
  
  On 1 January 1963, the AIEE and the IRE merged to form the Institute of Electrical and Electronics Engineers, or IEEE. At its formation, IEEE had 150,000 members, 140,000 of whom resided in the United States. Over the decades that followed, the social roles of the technologies under IEEE’s aegis continued to spread across the world and reach into more and more areas of people's lives.
  
IEEE, an association dedicated to advancing innovation and technological excellence for the benefit of humanity, is the world's largest technical professional society. It is designed to serve professionals involved in all aspects of the electrical, electronic, and computing fields and related areas of science and technology that underlie modern civilization.

IEEE's roots go back to 1884 when electricity began to become a major influence in society. There was one major established electrical industry, the telegraph, which since the 1840s had come to connect the world with a data communications system faster than the speed of transportation. The telephone and electric power and light industries had just gotten underway.
  
  
 # Data Representation: Numeric Conversions 
 
 The difference between decimal, binary and hexadecimal numbers 
 The numbers in a hex, binary are the same as decimal numbers: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9. The difference between a hex and a decimal is that a hex also contains letters.
 
 
 # Data Representation: Hexadecimal Color Representation 
 
  The representation: #ff016b
  In a RGB color space, hex #ff016b is composed of 100% red.
  
 
 
 
 
 
 
 
 
 # Information Systems for Business and Beyond: Chapter 3 
   # Software:
   
   # The roles of application, utility and operating system softwarea and example of each.
   Two subcategories of application software worth mentioning are utility software and programming software. Utility software includes software that allows you to fix or modify your computer in some way. Examples include antivirus software and disk defragmentation software. These types of software packages were invented to fill shortcomings in operating systems. Many times, a subsequent release of an operating system will include these utility functions as part of the operating system itself.
Programming software is software whose purpose is to make more software. Most of these programs provide programmers with an environment in which they can write the code, test it, and convert it into the format that can then be run on a computer. 

# The purpose of ERP software and provide an example.
ERP was developed to bring together an entire organization in one software application.

“A software application”: An ERP is a software application that is used by many of an organization’s employees.
“utilizing a central database”: All users of the ERP edit and save their information from the data source. What this means practically is that there is only one customer database, there is only one calculation for revenue, etc.
“that is implemented throughout the entire organization”: ERP systems include functionality that covers all of the essential components of a business. Further, an organization can purchase modules for its ERP system that match specific needs, such as manufacturing or planning. 

# The purpose of virtualization and describe how it differs from cloud computing. 

 Virtualization relies on software to simulate hardware functionality and create a virtual computer system. This enables IT organizations to run more than one virtual system – and multiple operating systems and applications – on a single server. The resulting benefits include economies of scale and greater efficiency.
 
 Virtualization vs. Cloud Computing:
 
Although equally buzz-worthy technologies, virtualization and cloud computing are not interchangeable. Virtualization is software that makes computing environments independent of physical infrastructure, while cloud computing is a service that delivers shared computing resources (software and/or data) on demand via the Internet. As complementary solutions, organizations can begin by virtualizing their servers and then moving to cloud computing for even greater agility and self-service.

  # The term software; 
Software is the set of instructions that tell the hardware what to do.

# Two primary categories of software; 
Software can be broadly divided into two categories: operating systems and application software. Operating systems manage the hardware and create the interface between the hardware and the user. Application software is the category of programs that do something useful for the user.

# The role ERP software plays in an organization;
The enterprise resource planning (ERP) system (sometimes just called enterprise software) was developed to bring together an entire organization in one software application. Simply put, an ERP system is a software application utilizing a central database that is implemented throughout the entire organization.

# Cloud computing and its advantages and disadvantages for use in an organization
# Advantages of Cloud Computing:
No software to install or upgrades to maintain.
Available from any computer that has access to the Internet.
Can scale to a large number of users easily.
New applications can be up and running very quickly.
Services can be leased for a limited time on an as-needed basis.
Your information is not lost if your hard disk crashes or your laptop is stolen.
You are not limited by the available memory or disk space on your computer

# Disadvantages of Cloud Computing:
Your information is stored on someone else’s computer – how safe is it?
You must have Internet access to use it. If you do not have access, you’re out of luck.
You are relying on a third-party to provide these services.

# The term open-source and identify its primary characteristics.

   Open-source software is software that makes the source code available for anyone to copy and use.
   
The open-source movement has led to the development of some of the most-used software in the world, including the Firefox browser, the Linux operating system, and the Apache web server. Many also think open-source software is superior to closed-source software. Because the source code is freely available, many programmers have contributed to open-source software projects, adding features and fixing bugs.
 


  # Virtualization 

# What types of problems are solved with virtualization? 
Data virtualization.
Desktop virtualization.
Server virtualization.
Operating system virtualization.
Network functions virtualization
 

# What role does hypervisor play in virtualization? 
 hypervisors separate the physical resources from the virtual environments—the things that need those resources. Hypervisors can sit on top of an operating system (like on a laptop) or be installed directly onto hardware (like a server), which is how most enterprises virtualize. Hypervisors take your physical resources and divide them up so that virtual environments can use them.
 










